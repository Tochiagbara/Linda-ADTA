# Insert your R code for Question 6 in here
# HINTS:
# in cv.glmnet() function choose  family='gaussian', type.measure="mse", alpha=0, nfolds=10 for the desired results
# optimized lamba is stored under the cv.glmnet() R object
# Minimum Mean CV Error is stored under cv.glmnet() R object
library(glmnet)
set.seed(5410)
cvfit <- cv.glmnet(x = trainData[, -1], y = trainData[, 1], alpha = 0, nfolds = 10)
# Insert your R code for Question 6 in here
# HINTS:
# in cv.glmnet() function choose  family='gaussian', type.measure="mse", alpha=0, nfolds=10 for the desired results
# optimized lamba is stored under the cv.glmnet() R object
# Minimum Mean CV Error is stored under cv.glmnet() R object
library(glmnet)
set.seed(5410)
cvfit <- cv.glmnet(x = trainData[, -1], y = trainData[, 1], alpha = 0, nfolds = 10)
# Insert your R code for Question 6 in here
# HINTS:
# in cv.glmnet() function choose  family='gaussian', type.measure="mse", alpha=0, nfolds=10 for the desired results
# optimized lamba is stored under the cv.glmnet() R object
# Minimum Mean CV Error is stored under cv.glmnet() R object
library(glmnet)
set.seed(5410)
cvfit <- cv.glmnet(x = trainData[, -1], y = trainData[, 1], alpha = 0, nfolds = 10)
# Insert your R code for Question 6 in here
# HINTS:
# in cv.glmnet() function choose  family='gaussian', type.measure="mse", alpha=0, nfolds=10 for the desired results
# optimized lamba is stored under the cv.glmnet() R object
# Minimum Mean CV Error is stored under cv.glmnet() R object
library(glmnet)
set.seed(5410)
#cvfit <- cv.glmnet(x = trainData[, -1], y = trainData[, 1], alpha = 0, nfolds = 10)
min_cvm <- min(cvfit$cvm)
# Insert your R code for Question 6 in here
# HINTS:
# in cv.glmnet() function choose  family='gaussian', type.measure="mse", alpha=0, nfolds=10 for the desired results
# optimized lamba is stored under the cv.glmnet() R object
# Minimum Mean CV Error is stored under cv.glmnet() R object
library(glmnet)
set.seed(5410)
#cvfit <- cv.glmnet(x = trainData[, -1], y = trainData[, 1], alpha = 0, nfolds = 10)
#min_cvm <- min(cvfit$cvm)
cat("The minimum mean cross-validated error is:", min_cvm, "\n")
y.train = trainData$logSalary
predictors.train = trainData[,-17]
y.test = testData$logSalary
predictors.test = testData[,-17]
# Optimize lambda using 10-fold cross validation
set.seed(5410)
# Optimize lambda using 10-fold cross validation, keep the default lambda selection
RidgeCV = cv.glmnet(as.matrix(predictors.train), y.train,
family='gaussian', type.measure="mse", alpha=0, nfolds=10)
y.train = trainData$logSalary
predictors.train = trainData[,-17]
y.test = testData$logSalary
predictors.test = testData[,-17]
# Optimize lambda using 10-fold cross validation
set.seed(5410)
# Optimize lambda using 10-fold cross validation, keep the default lambda selection
RidgeCV = cv.glmnet(as.matrix(predictors.train), y.train,
family='gaussian', type.measure="mse", alpha=0, nfolds=10)
# plot
plot(RidgeCV)
# check the values of lambda used in the fits
RidgeCV$lambda
# check the mean cross-validated error for each lambda used
RidgeCV$cvm
# get the minimum mean cross-validated error
min(RidgeCV$cvm)
# number of non-zero coefficients at each lambda. For Ridge, it is all same and equal to number of predictors
RidgeCV$nzero
# get the value of lambda which gives you the minimum cross-validated error
RidgeCV$lambda.min
# Use the best lambda and predict the target variable in the test set, calculate MSPE
RidgePredictTest<-predict(RidgeCV,s=RidgeCV$lambda.min,newx=as.matrix(predictors.test))
# Calculate the MSPE in the test set
MSPE_Ridge_test<-mean((RidgePredictTest-y.test)^2)
#NEXT STEP
# We used cross validation in the train data to get the optimal lambda
# We used test data to ESTIMATE test error with the best lambda found in the train data
#Now, REFIT the RIDGE Regression model on the FULL data set, use the value of lambda chosen by cross-validation  and check the coefficient estimates
# First, we fit Ridge Regression
set.seed(5410)
# write down the model , since we no longer need cross validation, we just use glmnet functiom (not the cv.glmnet function)
# we first create the object, then try to get the fitted value for a given lambda
FullRidgeModel<-glmnet(trainData[,-17], trainData$logSalary,family='gaussian', type.measure="mse", alpha=0)
# get the predicted values with optimal lambda found with cross validation
FullRidgeModelPredict<-predict(FullRidgeModel,type="coefficients", s=RidgeCV$lambda.min)
FullRidgeModelPredict
# Insert your R code for Question 7 in here
# HINTS:
# in cv.glmnet() function choose  family='gaussian', type.measure="mse", alpha=0, nfolds=10 for the desired results
# optimized lamba is stored under the cv.glmnet() R object
# Minimum Mean CV Error is stored under cv.glmnet() R object
# predictors and the target variable already defined
y.train = trainData$logSalary
predictors.train = trainData[,-17]
y.test = testData$logSalary
predictors.test = testData[,-17]
## PERFORM CROSS VALIDATION
set.seed(5410)
# Optimize lambda using 10-fold cross validation, keep the default lambda selection
LassoCV = cv.glmnet(as.matrix(predictors.train), y.train,
family='gaussian', type.measure="mse", alpha=1, nfolds=10)
# check the values of lambda used in the fits
LassoCV$lambda
# check the mean cross-validated error for each lambda used
LassoCV$cvm
# get the minimum mean cross-validated error
set.seed(5410)
# Insert your R code for Question 7 in here
# HINTS:
# in cv.glmnet() function choose  family='gaussian', type.measure="mse", alpha=0, nfolds=10 for the desired results
# optimized lamba is stored under the cv.glmnet() R object
# Minimum Mean CV Error is stored under cv.glmnet() R object
# predictors and the target variable already defined
y.train = trainData$logSalary
predictors.train = trainData[,-17]
y.test = testData$logSalary
predictors.test = testData[,-17]
## PERFORM CROSS VALIDATION
set.seed(5410)
# Optimize lambda using 10-fold cross validation, keep the default lambda selection
LassoCV = cv.glmnet(as.matrix(predictors.train), y.train,
family='gaussian', type.measure="mse", alpha=1, nfolds=10)
# check the values of lambda used in the fits
LassoCV$lambda
# check the mean cross-validated error for each lambda used
LassoCV$cvm
# get the minimum mean cross-validated error
min(LassoCV$cvm)
# optimal lambda
LassoCV$lambda.min
# number of non-zero coefficients at each lambda.
LassoCV$nzero
# number of features at the optimal lambda
LassoCV$nzero[LassoCV$lambda == LassoCV$lambda.min]
# Use the best lambda and predict the target variable in the test set with Lasso and  calculate MSPE
LassoPredictTest<-predict(LassoCV,s=LassoCV$lambda.min,newx=as.matrix(predictors.test))
set.seed(5410)
# Insert your R code for Question 7 in here
y.train = trainData$logSalary
predictors.train = trainData[,-17]
y.test = testData$logSalary
predictors.test = testData[,-17]
## PERFORM CROSS VALIDATION
set.seed(5410)
# Optimize lambda using 10-fold cross validation, keep the default lambda selection
LassoCV = cv.glmnet(as.matrix(predictors.train), y.train,
family='gaussian', type.measure="mse", alpha=1, nfolds=10)
# check the values of lambda used in the fits
LassoCV$lambda
# check the mean cross-validated error for each lambda used
LassoCV$cvm
# get the minimum mean cross-validated error
min(LassoCV$cvm)
# optimal lambda
LassoCV$lambda.min
# number of non-zero coefficients at each lambda.
LassoCV$nzero
# number of features at the optimal lambda
LassoCV$nzero[LassoCV$lambda == LassoCV$lambda.min]
# Use the best lambda and predict the target variable in the test set with Lasso and  calculate MSPE
LassoPredictTest<-predict(LassoCV,s=LassoCV$lambda.min,newx=as.matrix(predictors.test))
MSPE_Lasso_test<-mean((LassoPredictTest-y.test)^2)
set.seed(5410)
# write down the model with ALL observations
FullLassoModel<-glmnet(trainData[,-17], trainData$logSalary,family='gaussian', type.measure="mse", alpha=1)
# get the predicted values with optimal lambda
FullLassoModelPredict<-predict(FullLassoModel,type="coefficients", s=LassoCV$lambda.min)
round(FullLassoModelPredict,Â 3)
# Insert your R code for Question 7 in here
y.train = trainData$logSalary
predictors.train = trainData[,-17]
y.test = testData$logSalary
predictors.test = testData[,-17]
## PERFORM CROSS VALIDATION
set.seed(5410)
# Optimize lambda using 10-fold cross validation, keep the default lambda selection
LassoCV = cv.glmnet(as.matrix(predictors.train), y.train,
family='gaussian', type.measure="mse", alpha=1, nfolds=10)
# check the values of lambda used in the fits
LassoCV$lambda
# check the mean cross-validated error for each lambda used
LassoCV$cvm
# get the minimum mean cross-validated error
min(LassoCV$cvm)
# optimal lambda
LassoCV$lambda.min
# number of non-zero coefficients at each lambda.
LassoCV$nzero
# number of features at the optimal lambda
LassoCV$nzero[LassoCV$lambda == LassoCV$lambda.min]
# Use the best lambda and predict the target variable in the test set with Lasso and  calculate MSPE
LassoPredictTest<-predict(LassoCV,s=LassoCV$lambda.min,newx=as.matrix(predictors.test))
MSPE_Lasso_test<-mean((LassoPredictTest-y.test)^2)
set.seed(5410)
# write down the model with ALL observations
FullLassoModel<-glmnet(trainData[,-17], trainData$logSalary,family='gaussian', type.measure="mse", alpha=1)
# get the predicted values with optimal lambda
FullLassoModelPredict<-predict(FullLassoModel,type="coefficients", s=LassoCV$lambda.min)
round(FullLassoModelPredict,3)
set.seed(5410)
y.train = trainData$logSalary
predictors.train = trainData[,-17]
y.test = testData$logSalary
predictors.test = testData[,-17]
set.seed(5410)
# Optimize lambda using 10-fold cross validation, keep the default lambda selection
LassoCV = cv.glmnet(as.matrix(predictors.train), y.train,
family='gaussian', type.measure="mse", alpha=1, nfolds=10)
LassoCV$lambda
# check the mean cross-validated error for each lambda used
LassoCV$cvm
# get the minimum mean cross-validated error
min(LassoCV$cvm)
# optimal lambda
LassoCV$lambda.min
# number of non-zero coefficients at each lambda.
LassoCV$nzero
# number of features at the optimal lambda
LassoCV$nzero[LassoCV$lambda == LassoCV$lambda.min]
# Use the best lambda and predict the target variable in the test set with Lasso and  calculate MSPE
LassoPredictTest<-predict(LassoCV,s=LassoCV$lambda.min,newx=as.matrix(predictors.test))
MSPE_Lasso_test<-mean((LassoPredictTest-y.test)^2)
set.seed(5410)
FullLassoModel<-glmnet(trainData[,-17], trainData$logSalary,family='gaussian', type.measure="mse", alpha=1)
# get the predicted values with optimal lambda
FullLassoModelPredict<-predict(FullLassoModel,type="coefficients", s=LassoCV$lambda.min)
round(FullLassoModelPredict,3)
# Insert your R code for Question 7 in here
# HINTS: use coef() to extract the coefficients. Any coefficient with 0 estimate is dropped from the regression
y.train = trainData$logSalary
predictors.train = trainData[,-17]
y.test = testData$logSalary
predictors.test = testData[,-17]
set.seed(5410)
# Optimize lambda using 10-fold cross validation, keep the default lambda selection
LassoCV = cv.glmnet(as.matrix(predictors.train), y.train,
family='gaussian', type.measure="mse", alpha=1, nfolds=10)
#  Insert your R code for Question 7 in here
y.train = trainData$logSalary
predictors.train = trainData[,-17]
y.test = testData$logSalary
predictors.test = testData[,-17]
set.seed(5410)
# Optimize lambda using 10-fold cross validation, keep the default lambda selection
LassoCV = cv.glmnet(as.matrix(predictors.train), y.train,
family='gaussian', type.measure="mse", alpha=1, nfolds=10)
y.train = trainData$logSalary
predictors.train = trainData[,-17]
y.test = testData$logSalary
predictors.test = testData[,-17]
set.seed(5410)
# Optimize lambda using 10-fold cross validation, keep the default lambda selection
LassoCV = cv.glmnet(as.matrix(predictors.train), y.train,
family='gaussian', type.measure="mse", alpha=1, nfolds=10)
LassoCV$lambda
# check the mean cross-validated error for each lambda used
LassoCV$cvm
# get the minimum mean cross-validated error
min(LassoCV$cvm)
# optimal lambda
LassoCV$lambda.min
# number of non-zero coefficients at each lambda.
LassoCV$nzero
# number of features at the optimal lambda
LassoCV$nzero[LassoCV$lambda == LassoCV$lambda.min]
# Use the best lambda and predict the target variable in the test set with Lasso and  calculate MSPE
LassoPredictTest<-predict(LassoCV,s=LassoCV$lambda.min,newx=as.matrix(predictors.test))
MSPE_Lasso_test<-mean((LassoPredictTest-y.test)^2)
set.seed(5410)
FullLassoModel<-glmnet(trainData[,-17], trainData$logSalary,family='gaussian', type.measure="mse", alpha=1)
# get the predicted values with optimal lambda
FullLassoModelPredict<-predict(FullLassoModel,type="coefficients", s=LassoCV$lambda.min)
round(FullLassoModelPredict,3)
#  Insert your R code for Question 7 in here
y.train = trainData$logSalary
predictors.train = trainData[,-17]
y.test = testData$logSalary
predictors.test = testData[,-17]
set.seed(5410)
# Optimize lambda using 10-fold cross validation, keep the default lambda selection
LassoCV = cv.glmnet(as.matrix(predictors.train), y.train,
family='gaussian', type.measure="mse", alpha=1, nfolds=10)
LassoCV$lambda
# check the mean cross-validated error for each lambda used
LassoCV$cvm
# get the minimum mean cross-validated error
min(LassoCV$cvm)
# optimal lambda
LassoCV$lambda.min
# number of non-zero coefficients at each lambda.
LassoCV$nzero
# number of features at the optimal lambda
LassoCV$nzero[LassoCV$lambda == LassoCV$lambda.min]
# Use the best lambda and predict the target variable in the test set with Lasso and  calculate MSPE
LassoPredictTest<-predict(LassoCV,s=LassoCV$lambda.min,newx=as.matrix(predictors.test))
# Run this code chunk without altering it
# clear the session
rm(list=ls())
# We will need these libraries, if you will use others, just add in here
library(boot)
library(leaps)
library(MASS)
library(glmnet)
library(foreign)
# read data in R and remove player and team names, League, Division, Position and Div variables
set.seed(5410)
DataBaseball = read.csv("Data_RLab4.csv", header = TRUE,stringsAsFactors = TRUE)
DataBaseball<-DataBaseball[,-c(1,2, 16, 17,18,  22)]
# You can check to see if there is any missing values in the data
#sapply(DataBaseball, function(x) sum(is.na(x)))
# Do arandom split of the dataset into train and tests set by keeping 20% of the data in the test set.
shuffleid = sample(nrow(DataBaseball), 0.2 * nrow(DataBaseball))
testData = DataBaseball[shuffleid, ]
trainData = DataBaseball[-shuffleid, ]
model_full <- lm(logSalary ~ ., data = trainData)
summary(model_full)
model_full <- lm(logSalary ~ ., data = trainData)
summary(model_full)
# Assuming "model_full" is the name of the linear regression model object
# and "testData" is the name of the test dataset
pred <- predict(model_full, newdata = testData)
MSPE <- mean((testData$logSalary - predictions)^2)
# Assuming "model_full" is the name of the linear regression model object
# and "testData" is the name of the test dataset
pred <- predict(model_full, newdata = testData)
MSPE <- mean((testData$logSalary - pred)^2)
adjusted_R_squared <- 1 - (1 - summary(model_full)$r.squared) * ((nrow(testData) - 1)/(nrow(testData) - ncol(testData) - 1))
AIC_value <- AIC(model_full)
BIC_value <- BIC(model_full)
#data.frame(MSPE=,ADJRZ=,AIC=,BIC=)
library(glmnet)
# cv.glm() R object stores two information under delta (cv.glm()$delta). The first information gives the  cross-validation estimate of prediction error, MSPE, that is the answer.
set.seed(5410)
model <- glm(logSalary ~ ., data = trainData)
predictions <- predict(model, trainData)
cv5 <- cv.glm(trainData, model, K = 5)
mspe5 <- cv5$delta[1]
cv10 <- cv.glm(trainData, model, K = 10)
mspe10 <- cv10$delta[1]
loo <- cv.glm(trainData, model, K = nrow(trainData))
mspe_loo <- loo$delta[1]
# Load Library
library(leaps)
names(trainData)
# Get the column names for predictors: we need this to create a table of results
# exlcude the target variable from the list
col_names<-names(trainData)[-17]
bestsubsets_fullR2<-leaps(trainData[,-17], trainData$logSalary, method = "adjr2", nbest=1, names = col_names)
# Put them all in a table
table_bestsubset<-cbind(as.matrix(bestsubsets_fullR2$which),AdjR2=bestsubsets_fullR2$adjr2)
# Choose your best model by the one with the highest R square value
# Find  which row has the highest Adjusted R squares value
bestmodeladjr2 = which(bestsubsets_fullR2$adjr2==max(bestsubsets_fullR2$adjr2))
# Extract the coefficients of the best model
best.adjr2 = cbind(as.matrix(bestsubsets_fullR2$which),bestsubsets_fullR2$adjr2)[bestmodeladjr2,]
best.adjr2
y.train = trainData$logSalary
predictors.train = trainData[,-17]
y.test = testData$logSalary
predictors.test = testData[,-17]
# Optimize lambda using 10-fold cross validation
set.seed(5410)
# Optimize lambda using 10-fold cross validation, keep the default lambda selection
RidgeCV = cv.glmnet(as.matrix(predictors.train), y.train,
family='gaussian', type.measure="mse", alpha=0, nfolds=10)
# plot
plot(RidgeCV)
# check the values of lambda used in the fits
RidgeCV$lambda
# check the mean cross-validated error for each lambda used
RidgeCV$cvm
# get the minimum mean cross-validated error
min(RidgeCV$cvm)
# number of non-zero coefficients at each lambda. For Ridge, it is all same and equal to number of predictors
RidgeCV$nzero
# get the value of lambda which gives you the minimum cross-validated error
RidgeCV$lambda.min
# Use the best lambda and predict the target variable in the test set, calculate MSPE
RidgePredictTest<-predict(RidgeCV,s=RidgeCV$lambda.min,newx=as.matrix(predictors.test))
# Calculate the MSPE in the test set
MSPE_Ridge_test<-mean((RidgePredictTest-y.test)^2)
#NEXT STEP
# We used cross validation in the train data to get the optimal lambda
# First, we fit Ridge Regression
set.seed(5410)
# write down the model , since we no longer need cross validation, we just use glmnet functiom (not the cv.glmnet function)
# we first create the object, then try to get the fitted value for a given lambda
FullRidgeModel<-glmnet(trainData[,-17], trainData$logSalary,family='gaussian', type.measure="mse", alpha=0)
# get the predicted values with optimal lambda found with cross validation
FullRidgeModelPredict<-predict(FullRidgeModel,type="coefficients", s=RidgeCV$lambda.min)
FullRidgeModelPredict
y.train = trainData$logSalary
predictors.train = trainData[,-17]
y.test = testData$logSalary
predictors.test = testData[,-17]
set.seed(5410)
# Optimize lambda using 10-fold cross validation, keep the default lambda selection
LassoCV = cv.glmnet(as.matrix(predictors.train), y.train,
family='gaussian', type.measure="mse", alpha=1, nfolds=10)
LassoCV$lambda
# check the mean cross-validated error for each lambda used
LassoCV$cvm
# get the minimum mean cross-validated error
min(LassoCV$cvm)
# optimal lambda
LassoCV$lambda.min
# number of non-zero coefficients at each lambda.
LassoCV$nzero
# number of features at the optimal lambda
LassoCV$nzero[LassoCV$lambda == LassoCV$lambda.min]
# Use the best lambda and predict the target variable in the test set with Lasso and  calculate MSPE
LassoPredictTest<-predict(LassoCV,s=LassoCV$lambda.min,newx=as.matrix(predictors.test))
MSPE_Lasso_test<-mean((LassoPredictTest-y.test)^2)
set.seed(5410)
FullLassoModel<-glmnet(trainData[,-17], trainData$logSalary,family='gaussian', type.measure="mse", alpha=1)
# get the predicted values with optimal lambda
FullLassoModelPredict<-predict(FullLassoModel,type="coefficients", s=LassoCV$lambda.min)
round(FullLassoModelPredict,3)
# Insert your R code for Question 7 in here
# HINTS: use coef() to extract the coefficients. Any coefficient with 0 estimate is dropped from the regression
y.train = trainData$logSalary
predictors.train = trainData[,-17]
y.test = testData$logSalary
predictors.test = testData[,-17]
set.seed(5410)
# Optimize lambda using 10-fold cross validation, keep the default lambda selection
LassoCV = cv.glmnet(as.matrix(predictors.train), y.train,
family='gaussian', type.measure="mse", alpha=1, nfolds=10)
#  Insert your R code for Question 7 in here
y.train = trainData$logSalary
predictors.train = trainData[,-17]
y.test = testData$logSalary
predictors.test = testData[,-17]
set.seed(5410)
# Optimize lambda using 10-fold cross validation, keep the default lambda selection
LassoCV = cv.glmnet(as.matrix(predictors.train), y.train,
family='gaussian', type.measure="mse", alpha=1, nfolds=10)
LassoCV$lambda
# check the mean cross-validated error for each lambda used
LassoCV$cvm
# get the minimum mean cross-validated error
min(LassoCV$cvm)
# optimal lambda
LassoCV$lambda.min
# number of non-zero coefficients at each lambda.
LassoCV$nzero
# number of features at the optimal lambda
LassoCV$nzero[LassoCV$lambda == LassoCV$lambda.min]
# Use the best lambda and predict the target variable in the test set with Lasso and  calculate MSPE
LassoPredictTest<-predict(LassoCV,s=LassoCV$lambda.min,newx=as.matrix(predictors.test))
# Assuming "model_full" is the name of the linear regression model object
# and "testData" is the name of the test dataset
pred <- predict(model_full, newdata = testData)
MSPE <- mean((testData$logSalary - pred)^2)
adjusted_R_squared <- 1 - (1 - summary(model_full)$r.squared) * ((nrow(testData) - 1)/(nrow(testData) - ncol(testData) - 1))
AIC_value <- AIC(model_full)
BIC_value <- BIC(model_full)
#data.frame(MSPE=,ADJRZ=,AIC=,BIC=)
AIC_value
BIC_value
# Assuming "model_full" is the name of the linear regression model object
# and "testData" is the name of the test dataset
pred <- predict(model_full, newdata = testData)
MSPE <- mean((testData$logSalary - pred)^2)
adjusted_R_squared <- 1 - (1 - summary(model_full)$r.squared) * ((nrow(testData) - 1)/(nrow(testData) - ncol(testData) - 1))
AIC_value <- AIC(model_full)
BIC_value <- BIC(model_full)
#data.frame(MSPE=,ADJRZ=,AIC=,BIC=)
print("The AIC Value : ",AIC_value)
# Assuming "model_full" is the name of the linear regression model object
# and "testData" is the name of the test dataset
pred <- predict(model_full, newdata = testData)
MSPE <- mean((testData$logSalary - pred)^2)
adjusted_R_squared <- 1 - (1 - summary(model_full)$r.squared) * ((nrow(testData) - 1)/(nrow(testData) - ncol(testData) - 1))
AIC_value <- AIC(model_full)
BIC_value <- BIC(model_full)
#data.frame(MSPE=,ADJRZ=,AIC=,BIC=)
Print("The AIC Value : ",AIC_value)
# Assuming "model_full" is the name of the linear regression model object
# and "testData" is the name of the test dataset
pred <- predict(model_full, newdata = testData)
MSPE <- mean((testData$logSalary - pred)^2)
adjusted_R_squared <- 1 - (1 - summary(model_full)$r.squared) * ((nrow(testData) - 1)/(nrow(testData) - ncol(testData) - 1))
AIC_value <- AIC(model_full)
BIC_value <- BIC(model_full)
#data.frame(MSPE=,ADJRZ=,AIC=,BIC=)
print("The AIC Value : ",AIC_value)
# Assuming "model_full" is the name of the linear regression model object
# and "testData" is the name of the test dataset
pred <- predict(model_full, newdata = testData)
MSPE <- mean((testData$logSalary - pred)^2)
adjusted_R_squared <- 1 - (1 - summary(model_full)$r.squared) * ((nrow(testData) - 1)/(nrow(testData) - ncol(testData) - 1))
AIC_value <- AIC(model_full)
BIC_value <- BIC(model_full)
#data.frame(MSPE=,ADJRZ=,AIC=,BIC=)
print(paste("The AIC Value : ",AIC_value))
print(paste("The BIC Value : ",BIC_value))
# Assuming "model_full" is the name of the linear regression model object
# and "testData" is the name of the test dataset
pred <- predict(model_full, newdata = testData)
MSPE <- mean((testData$logSalary - pred)^2)
adjusted_R_squared <- 1 - (1 - summary(model_full)$r.squared) * ((nrow(testData) - 1)/(nrow(testData) - ncol(testData) - 1))
AIC_value <- AIC(model_full)
BIC_value <- BIC(model_full)
#data.frame(MSPE=,ADJRZ=,AIC=,BIC=)
print(paste("The AIC Value : ",round(AIC_value,3)))
print(paste("The BIC Value : ",round(BIC_value,3)))
install.packages("githubinstall")
setwd("C:/Users/Linda/Documents/GitHub")
